<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>All Of Me</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="+++title         = “IOS音频编程之变声处理”tags         = [“Audio Unit”,”变声处理”]categories    = [“IOS”]date        = “2016-06-09”+++
#IOS音频编程之变声处理
###需求：耳塞Mic实时录音，变声处理后实时输出

初始化###程序使用44100HZ的频率对原始的音频数据进行采样，并在音频">
<meta property="og:type" content="article">
<meta property="og:title" content="All Of Me">
<meta property="og:url" content="http://yoursite.com/2016/06/08/IOS音频变成之变声处理/index.html">
<meta property="og:site_name" content="All Of Me">
<meta property="og:description" content="+++title         = “IOS音频编程之变声处理”tags         = [“Audio Unit”,”变声处理”]categories    = [“IOS”]date        = “2016-06-09”+++
#IOS音频编程之变声处理
###需求：耳塞Mic实时录音，变声处理后实时输出

初始化###程序使用44100HZ的频率对原始的音频数据进行采样，并在音频">
<meta property="og:image" content="https://raw.githubusercontent.com/JustinYangJing/Resource/master/Image/Audio/1.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JustinYangJing/Resource/master/Image/Audio/2.png">
<meta property="og:image" content="https://raw.githubusercontent.com/JustinYangJing/Resource/master/Image/Audio/3.png">
<meta property="og:updated_time" content="2016-06-09T11:46:12.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="All Of Me">
<meta name="twitter:description" content="+++title         = “IOS音频编程之变声处理”tags         = [“Audio Unit”,”变声处理”]categories    = [“IOS”]date        = “2016-06-09”+++
#IOS音频编程之变声处理
###需求：耳塞Mic实时录音，变声处理后实时输出

初始化###程序使用44100HZ的频率对原始的音频数据进行采样，并在音频">
<meta name="twitter:image" content="https://raw.githubusercontent.com/JustinYangJing/Resource/master/Image/Audio/1.png">
  
    <link rel="alternate" href="/atom.xml" title="All Of Me" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">All Of Me</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-IOS音频变成之变声处理" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/06/08/IOS音频变成之变声处理/" class="article-date">
  <time datetime="2016-06-08T10:31:34.000Z" itemprop="datePublished">2016-06-08</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>+++<br>title         = “IOS音频编程之变声处理”<br>tags         = [“Audio Unit”,”变声处理”]<br>categories    = [“IOS”]<br>date        = “2016-06-09”<br>+++</p>
<p>#IOS音频编程之变声处理</p>
<p>###需求：耳塞Mic实时录音，变声处理后实时输出</p>
<hr>
<h2 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h2><p>###程序使用44100HZ的频率对原始的音频数据进行采样，并在音频输入的回调中处理采样的数据。<br>1）对AVAudioSession的一些设置</p>
<pre><code>NSError *error;
self.session = [AVAudioSession sharedInstance];
[self.session setCategory:AVAudioSessionCategoryPlayAndRecord error:&amp;error];
handleError(error);
//route变化监听
[[NSNotificationCenter defaultCenter] addObserver:self selector:@selector(audioSessionRouteChangeHandle:) name:AVAudioSessionRouteChangeNotification object:self.session];

[self.session setPreferredIOBufferDuration:0.005 error:&amp;error];
handleError(error);
[self.session setPreferredSampleRate:kSmaple error:&amp;error];
handleError(error);

[self.session setActive:YES error:&amp;error];
handleError(error);
</code></pre><p> <code>setPreferredIOBufferDurations</code>文档上解释<code>change to the I/O buffer duration</code>,具体解释参看官方文档。我把它理解为在每次调用输入或输出的回调，能提供多长时间(由设置的这个值决定)的音频数据。但当我用0.005和0.93分别设置它的时候，发现回调中的<code>inNumberFrames</code>的值并未改变，一直是512，相当于每次输入或输出提供了512/44100=0.0116s的数据。（<strong>设置有问题?</strong>）</p>
<p> <code>setPreferredSampleRate</code>设置对音频数据的采样率。</p>
<p> 2)获取AudioComponentInstance</p>
<pre><code>//Obtain a RemoteIO unit instance
AudioComponentDescription acd;
acd.componentType = kAudioUnitType_Output;
acd.componentSubType = kAudioUnitSubType_RemoteIO;
acd.componentFlags = 0;
acd.componentFlagsMask = 0;
acd.componentManufacturer = kAudioUnitManufacturer_Apple;
AudioComponent inputComponent = AudioComponentFindNext(NULL, &amp;acd);
AudioComponentInstanceNew(inputComponent, &amp;_toneUnit);
</code></pre><p> 3）对AudioComponentInstance的一些初始化设置<br> <center><br>    <img style="display:block;width:100%;" src="https://raw.githubusercontent.com/JustinYangJing/Resource/master/Image/Audio/1.png" alt="I/O unit"><br> </center><br> 这张图蓝色框中的部分就是一个<code>I/O Unit</code>(<code>AudioComponentInstance</code>的实例).图中的<code>Element 0</code>连接<code>Speaker</code>,也叫<code>Output Bus</code>;<code>Element 1</code>连接<code>Mic</code>,也叫<code>Input Bus</code>.初始化它，就是对再这些Bus上的音频流的格式，设置输入输出的回调函数等。</p>
<pre><code> UInt32 enable = 1;
AudioUnitSetProperty(_toneUnit,
                     kAudioOutputUnitProperty_EnableIO,
                     kAudioUnitScope_Input,
                     kInputBus,
                     &amp;enable,
                     sizeof(enable));
AudioUnitSetProperty(_toneUnit,
                     kAudioOutputUnitProperty_EnableIO,
                     kAudioUnitScope_Output,
                     kOutoutBus, &amp;enable, sizeof(enable));

mAudioFormat.mSampleRate         = kSmaple;//采样率
mAudioFormat.mFormatID           = kAudioFormatLinearPCM;//PCM采样
mAudioFormat.mFormatFlags        = kAudioFormatFlagIsSignedInteger | kAudioFormatFlagIsPacked;
mAudioFormat.mFramesPerPacket    = 1;//每个数据包多少帧
mAudioFormat.mChannelsPerFrame   = 1;//1单声道，2立体声
mAudioFormat.mBitsPerChannel     = 16;//语音每采样点占用位数
mAudioFormat.mBytesPerFrame      = mAudioFormat.mBitsPerChannel*mAudioFormat.mChannelsPerFrame/8;//每帧的bytes数
mAudioFormat.mBytesPerPacket     = mAudioFormat.mBytesPerFrame*mAudioFormat.mFramesPerPacket;//每个数据包的bytes总数，每帧的bytes数＊每个数据包的帧数
mAudioFormat.mReserved           = 0;

CheckError(AudioUnitSetProperty(_toneUnit,
                                kAudioUnitProperty_StreamFormat,
                                kAudioUnitScope_Input, kOutoutBus,
                                &amp;mAudioFormat, sizeof(mAudioFormat)),
           &quot;couldn&apos;t set the remote I/O unit&apos;s output client format&quot;);
CheckError(AudioUnitSetProperty(_toneUnit,
                                kAudioUnitProperty_StreamFormat,
                                kAudioUnitScope_Output, kInputBus,
                                &amp;mAudioFormat, sizeof(mAudioFormat)),
           &quot;couldn&apos;t set the remote I/O unit&apos;s input client format&quot;);

CheckError(AudioUnitSetProperty(_toneUnit,
                                kAudioOutputUnitProperty_SetInputCallback,
                                kAudioUnitScope_Output,
                                kInputBus,
                                &amp;_inputProc, sizeof(_inputProc)),
           &quot;couldnt set remote i/o render callback for input&quot;);

CheckError(AudioUnitSetProperty(_toneUnit,
                                kAudioUnitProperty_SetRenderCallback,
                                kAudioUnitScope_Input,
                                kOutoutBus,
                                &amp;_outputProc, sizeof(_outputProc)),
           &quot;couldnt set remote i/o render callback for output&quot;);

CheckError(AudioUnitInitialize(_toneUnit),
           &quot;couldn&apos;t initialize the remote I/O unit&quot;);
</code></pre><blockquote>
<p>注意<code>kAudioUnitScope_Output/kAudioUnitScope_Input</code>和<code>kOutput/kInput</code>的组合。设置输入输出使能时，Scope_Input下的kInput直接和Mic相连，所以是选用它们两;设置输出使能也类似。而设置音频的格式时，要选用Scope_Input下的kOutput和Scope_OutPut下的kInput,如果组合错误，为会返回-10865的错误码，意思说设置了只读属性，而在官方文档中也有说明,This hardware connection—at the input scope of element 1—is opaque to you. Your first access to audio data entering from the input hardware is at the output scope of element 1, output scope of element 0 is opaque。(<strong>疑问？在设置输入输出回调时以及Scope选择Input和Output以及Global都可以，但是官方文档中说<code>Your first access to audio data entering from the input hardware is at the output scope of element 1</code></strong>)</p>
</blockquote>
<p>##音频处理</p>
<p>###预备知识<br>变声操作实际是对声音信号的频谱进行搬移，在时域中乘以一个三角函数相当于在频域上进行了频谱的搬移。但使得频谱搬移了±𝑓。由下图傅里叶变化公式说明<br><img style="display:block;width:100%;" src="https://raw.githubusercontent.com/JustinYangJing/Resource/master/Image/Audio/2.png" alt="Fourier"><br>频谱搬移后，要把搬移的F(w-w。)的部分滤除。将声音的原始PCM放到Matlab中分析出频谱，然后进行搬移(<strong>实际上，我滤波这一步是失败的，还请小伙伴们告知我应该选一个怎样的滤波器</strong>)</p>
<p>1）写一个专门手机原始声音数据的程序，将声音数据保存到模拟上(用模拟器收集的声音，方便直接将写入到沙盒中的文件拷出来)。</p>
<p>2) 将声音数据用matlab读出来(注意模拟器和matlab处理数据时的大小端，专门把数据转换读出来看了，两边都应该是小端模式)，并分析和频移其频谱<br>matlab代码</p>
<pre><code>FID=fopen(&apos;record.txt&apos;,&apos;r&apos;);
fseek(FID,0,&apos;eof&apos;);
len=ftell(FID);
frewind(FID);
A=fread(FID,len/2,&apos;short&apos;);
A=A*1.0-mean(A);
Y=fft(A);
Fs=44100;
f=Fs*(0:length(A)/2 - 1)/length(A);
subplot(211);
plot(f,abs(Y(1:length(A)/2)));
k=0:length(A)-1;
cos_y=cos(2*pi*1000*k/44100);
cos_y=cos_y&apos;;
A2=A.*cos_y;
Y2=fft(A2);
subplot(212);
plot(f,abs(Y2(1:length(A)/2)));
</code></pre><p><img style="display:block;width:100%;" src="https://raw.githubusercontent.com/JustinYangJing/Resource/master/Image/Audio/3.png" alt="FFT "></p>
<p><strong>原始信号的频谱从0频开始?频率1000Hz后，虑除的就是小于1000hz的频率？实际在我的程序中对频谱只进行了200hz的搬移，那选一个大于200hz的IIR高通滤波器？</strong></p>
<p>3）用matlab设计滤波器，并得到滤波器参数.我用matlab的fdatool工具设计了一个5阶的IIR高通滤波器，截止频率为200hz。导出参数，用<code>[Bb,Ba]=sos2tf(SOS,G);</code>得出滤波器参数。</p>
<p>4）得到的Bb和Ba参数后，可以直接代入输入输出的差分方程得出滤波器的输出y(n)</p>
<p>###音频输入输出回调函数处理<br>1）输入回调</p>
<pre><code>OSStatus inputRenderTone(
                     void *inRefCon,
                     AudioUnitRenderActionFlags     *ioActionFlags,
                     const AudioTimeStamp         *inTimeStamp,
                     UInt32                         inBusNumber,
                     UInt32                         inNumberFrames,
                     AudioBufferList             *ioData)

{
ViewController *THIS=(__bridge ViewController*)inRefCon;

AudioBufferList bufferList;
bufferList.mNumberBuffers = 1;
bufferList.mBuffers[0].mData = NULL;
bufferList.mBuffers[0].mDataByteSize = 0;
OSStatus status = AudioUnitRender(THIS-&gt;_toneUnit,
                                  ioActionFlags,
                                  inTimeStamp,
                                  kInputBus,
                                  inNumberFrames,
                                  &amp;bufferList);

SInt16 *rece = (SInt16 *)bufferList.mBuffers[0].mData;
for (int i = 0; i &lt; inNumberFrames; i++) {
    rece[i] = rece[i]*THIS-&gt;_convertCos[i];//频谱搬移
}

RawData *rawData = &amp;THIS-&gt;_rawData;
//距离最大位置还有mDataByteSize/2 那就直接memcpy,否则要一个一个字节拷贝
if((rawData-&gt;rear+bufferList.mBuffers[0].mDataByteSize/2) &lt;= kRawDataLen){
    memcpy((uint8_t *)&amp;(rawData-&gt;receiveRawData[rawData-&gt;rear]), bufferList.mBuffers[0].mData, bufferList.mBuffers[0].mDataByteSize);
    rawData-&gt;rear = (rawData-&gt;rear+bufferList.mBuffers[0].mDataByteSize/2);
}else{
    uint8_t *pIOdata = (uint8_t *)bufferList.mBuffers[0].mData;
    for (int i = 0; i &lt; rawData-&gt;rear+bufferList.mBuffers[0].mDataByteSize; i+=2) {
        SInt16 data = pIOdata[i] | pIOdata[i+1]&lt;&lt;8;
        rawData-&gt;receiveRawData[rawData-&gt;rear] = data;
        rawData-&gt;rear = (rawData-&gt;rear+1)%kRawDataLen;
    }
}
return status;
}
</code></pre><blockquote>
<p>在频移的处理时，本来要对频移后的序列滤波的，<strong>但是滤波后，全部是杂音</strong>，所以删除掉了这部分代码，在提供的完整代码中有这部分删除掉的代码。存储数据中循环队列来存。</p>
</blockquote>
<p>2）输出回调</p>
<pre><code>OSStatus outputRenderTone(
                      void *inRefCon,
                      AudioUnitRenderActionFlags     *ioActionFlags,
                      const AudioTimeStamp         *inTimeStamp,
                      UInt32                         inBusNumber,
                      UInt32                         inNumberFrames,
                      AudioBufferList             *ioData)

{
ViewController *THIS=(__bridge ViewController*)inRefCon;

SInt16 *outSamplesChannelLeft   = (SInt16 *)ioData-&gt;mBuffers[0].mData;
RawData *rawData = &amp;THIS-&gt;_rawData;
for (UInt32 frameNumber = 0; frameNumber &lt; inNumberFrames; ++frameNumber) {
   if (rawData-&gt;front != rawData-&gt;rear) {
        outSamplesChannelLeft[frameNumber] = (rawData-&gt;receiveRawData[rawData-&gt;front]);
        rawData-&gt;front = (rawData-&gt;front+1)%kRawDataLen;

    }
}
return 0;
}
</code></pre><p>以上实现了对音频的实时录入变声后实时输出。没有滤波，听起来声音有点怪。😂😂😂大学的时候学的数字信号处理已经还给老师，关于信号处理这部分还请知道的小伙伴指点指点,想实现男女声音转化的效果。</p>
<p><a href="https://github.com/JustinYangJing/ConvertVoiceTest.git" target="_blank" rel="external">代码下载地址</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/06/08/IOS音频变成之变声处理/" data-id="cip8iacq90001hc89hq2u4g7e" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2016/04/23/Xcode使用Cocoa Touch Framework新建Framework/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title"></div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/06/">June 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/04/">April 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/02/">February 2016</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2016/06/08/IOS音频变成之变声处理/">(no title)</a>
          </li>
        
          <li>
            <a href="/2016/04/23/Xcode使用Cocoa Touch Framework新建Framework/">(no title)</a>
          </li>
        
          <li>
            <a href="/2016/04/23/ScrollView自动布局/">(no title)</a>
          </li>
        
          <li>
            <a href="/2016/02/10/创建私有库/">(no title)</a>
          </li>
        
          <li>
            <a href="/2016/02/10/lantern翻墙以及手机使用Http代理翻墙/">(no title)</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2016 Justin Yang<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>